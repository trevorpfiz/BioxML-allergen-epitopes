{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ea7ccee-e2ff-4fb0-9fd7-1d38f63e5b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=false\n",
      "Collecting esm\n",
      "  Using cached esm-3.0.5-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: torch>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from esm) (2.3.1.post100)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.11/site-packages (from esm) (0.18.1a0+405940f)\n",
      "Collecting torchtext (from esm)\n",
      "  Using cached torchtext-0.18.0-cp311-cp311-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (from esm) (4.38.2)\n",
      "Requirement already satisfied: ipython in /opt/conda/lib/python3.11/site-packages (from esm) (8.26.0)\n",
      "Collecting einops (from esm)\n",
      "  Using cached einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting biotite==0.41.2 (from esm)\n",
      "  Using cached biotite-0.41.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.1 kB)\n",
      "Collecting msgpack-numpy (from esm)\n",
      "  Using cached msgpack_numpy-0.4.8-py2.py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting biopython (from esm)\n",
      "  Using cached biopython-1.84-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.11/site-packages (from esm) (1.4.2)\n",
      "Requirement already satisfied: brotli in /opt/conda/lib/python3.11/site-packages (from esm) (1.1.0)\n",
      "Requirement already satisfied: attrs in /opt/conda/lib/python3.11/site-packages (from esm) (23.2.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from esm) (2.2.2)\n",
      "Requirement already satisfied: cloudpathlib in /opt/conda/lib/python3.11/site-packages (from esm) (0.18.1)\n",
      "Requirement already satisfied: tenacity in /opt/conda/lib/python3.11/site-packages (from esm) (8.5.0)\n",
      "Requirement already satisfied: msgpack>=0.5.6 in /opt/conda/lib/python3.11/site-packages (from biotite==0.41.2->esm) (1.0.8)\n",
      "Requirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.11/site-packages (from biotite==0.41.2->esm) (3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in /opt/conda/lib/python3.11/site-packages (from biotite==0.41.2->esm) (1.26.4)\n",
      "Requirement already satisfied: requests>=2.12 in /opt/conda/lib/python3.11/site-packages (from biotite==0.41.2->esm) (2.32.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch>=2.2.0->esm) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch>=2.2.0->esm) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=2.2.0->esm) (1.13.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.2.0->esm) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch>=2.2.0->esm) (2023.6.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.11/site-packages (from ipython->esm) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.11/site-packages (from ipython->esm) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.11/site-packages (from ipython->esm) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/conda/lib/python3.11/site-packages (from ipython->esm) (3.0.47)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.11/site-packages (from ipython->esm) (2.18.0)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.11/site-packages (from ipython->esm) (0.6.2)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /opt/conda/lib/python3.11/site-packages (from ipython->esm) (5.14.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.11/site-packages (from ipython->esm) (4.9.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->esm) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->esm) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->esm) (2024.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn->esm) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn->esm) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn->esm) (3.5.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from torchtext->esm) (4.66.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.11/site-packages (from torchvision->esm) (10.4.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.11/site-packages (from transformers->esm) (0.24.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers->esm) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers->esm) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers->esm) (2024.7.24)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.11/site-packages (from transformers->esm) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers->esm) (0.4.4)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.11/site-packages (from jedi>=0.16->ipython->esm) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.11/site-packages (from pexpect>4.3->ipython->esm) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.11/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython->esm) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->esm) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.12->biotite==0.41.2->esm) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.12->biotite==0.41.2->esm) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.12->biotite==0.41.2->esm) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.12->biotite==0.41.2->esm) (2024.7.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=2.2.0->esm) (2.1.5)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython->esm) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython->esm) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython->esm) (0.2.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=2.2.0->esm) (1.3.0)\n",
      "Using cached esm-3.0.5-py3-none-any.whl (148 kB)\n",
      "Using cached biotite-0.41.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.0 MB)\n",
      "Using cached biopython-1.84-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "Using cached einops-0.8.0-py3-none-any.whl (43 kB)\n",
      "Using cached msgpack_numpy-0.4.8-py2.py3-none-any.whl (6.9 kB)\n",
      "Using cached torchtext-0.18.0-cp311-cp311-manylinux1_x86_64.whl (2.0 MB)\n",
      "Installing collected packages: msgpack-numpy, einops, biopython, biotite, torchtext, esm\n",
      "Successfully installed biopython-1.84 biotite-0.41.2 einops-0.8.0 esm-3.0.5 msgpack-numpy-0.4.8 torchtext-0.18.0\n",
      "Collecting py3Dmol\n",
      "  Using cached py3Dmol-2.4.0-py2.py3-none-any.whl.metadata (1.9 kB)\n",
      "Using cached py3Dmol-2.4.0-py2.py3-none-any.whl (7.0 kB)\n",
      "Installing collected packages: py3Dmol\n",
      "Successfully installed py3Dmol-2.4.0\n"
     ]
    }
   ],
   "source": [
    "%set_env TOKENIZERS_PARALLELISM=false\n",
    "!pip install esm\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "!pip install py3Dmol\n",
    "import py3Dmol\n",
    "\n",
    "from esm.utils.structure.protein_chain import ProteinChain\n",
    "from esm.sdk import client\n",
    "from esm.sdk.api import (\n",
    "    ESMProtein,\n",
    "    GenerationConfig,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3ab108b-8499-4a8a-9436-5d09c173675b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Token from Forge console:  ········\n"
     ]
    }
   ],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "token = getpass(\"Token from Forge console: \")\n",
    "model = client(\n",
    "    model=\"esm3-small-2024-08\",\n",
    "    url=\"https://forge.evolutionaryscale.ai\",\n",
    "    token=token,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e483a0c-91ea-4b7c-914c-809651abeff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain ID: A, Number of residues: 292\n",
      "Chain ID: B, Number of residues: 250\n",
      "Chain ID: C, Number of residues: 249\n",
      "Chain ID: D, Number of residues: 236\n",
      "Chain ID: E, Number of residues: 108\n",
      "Chain ID: F, Number of residues: 104\n",
      "Chain ID: G, Number of residues: 235\n",
      "Chain ID: H, Number of residues: 218\n",
      "Chain ID: I, Number of residues: 258\n",
      "Chain ID: J, Number of residues: 270\n",
      "COMPND    MOL_ID: 1;\n",
      "COMPND   2 MOLECULE: 13T1 HEAVY CHAIN;\n",
      "COMPND   3 CHAIN: A, G;\n",
      "COMPND   4 ENGINEERED: YES;\n",
      "COMPND   5 MOL_ID: 2;\n",
      "COMPND   6 MOLECULE: 13T1 LIGHT CHAIN;\n",
      "COMPND   7 CHAIN: B, H;\n",
      "COMPND   8 ENGINEERED: YES;\n",
      "COMPND   9 MOL_ID: 3;\n",
      "COMPND  10 MOLECULE: 22S1 HEAVY CHAIN;\n",
      "COMPND  11 CHAIN: C, I;\n",
      "COMPND  12 ENGINEERED: YES;\n",
      "COMPND  13 MOL_ID: 4;\n",
      "COMPND  14 MOLECULE: 22S1 LIGHT CHAIN;\n",
      "COMPND  15 CHAIN: D, J;\n",
      "COMPND  16 ENGINEERED: YES;\n",
      "COMPND  17 MOL_ID: 5;\n",
      "COMPND  18 MOLECULE: ARA H 2 ALLERGEN;\n",
      "COMPND  19 CHAIN: E, F;\n",
      "COMPND  20 ENGINEERED: YES\n"
     ]
    }
   ],
   "source": [
    "from Bio.PDB import PDBParser\n",
    "\n",
    "# Load the structure from the PDB ID\n",
    "parser = PDBParser(QUIET=True)\n",
    "structure = parser.get_structure(\"structure\", \"./8db4.pdb\")\n",
    "\n",
    "# Iterate over the chains in the structure\n",
    "for model in structure:\n",
    "    for chain in model:\n",
    "        print(f\"Chain ID: {chain.id}, Number of residues: {len(chain)}\")\n",
    "\n",
    "with open('8db4.pdb', 'r') as pdb_file:\n",
    "    for line in pdb_file:\n",
    "        if line.startswith('COMPND'):\n",
    "            print(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc6ac490-0ee7-45a5-98e2-7279b9711dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb_id = \"8DB4\"  # PDB ID corresponding to Ara h 2 bound by two neutralizing antibodies\n",
    "pdb_file = \"./8db4.pdb\"\n",
    "chain_id = \"E\"  # Chain ID corresponding to Ara h 2 in the PDB structure\n",
    "arah2_chain = ProteinChain.from_pdb(pdb_file, chain_id)\n",
    "# Alternatively, we could have used ProteinChain.from_pdb() to load a protein structure from a local PDB file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d34d67a1-03d8-4865-b7e4-bcdf8a902250",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'arah2_chain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43marah2_chain\u001b[49m\u001b[38;5;241m.\u001b[39msequence)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'arah2_chain' is not defined"
     ]
    }
   ],
   "source": [
    "print(arah2_chain.sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d40f30d-f814-44a8-b0ad-9023eb3c3165",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"atom37_positions shape: \", arah2_chain.atom37_positions.shape)\n",
    "print(arah2_chain.atom37_positions[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad708600-1802-431b-a9f1-a4f16bfcbcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we can create a `py3Dmol` view object\n",
    "view = py3Dmol.view(width=500, height=500)\n",
    "# py3Dmol requires the atomic coordinates to be in PDB format, so we convert the `ProteinChain` object to a PDB string\n",
    "pdb_str = arah2_chain.to_pdb_string()\n",
    "# Load the PDB string into the `py3Dmol` view object\n",
    "view.addModel(pdb_str, \"pdb\")\n",
    "# Set the style of the protein chain\n",
    "view.setStyle({\"cartoon\": {\"color\": \"spectrum\"}})\n",
    "# Zoom in on the protein chain\n",
    "view.zoomTo()\n",
    "# Display the protein chain\n",
    "view.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52d6703f-b46b-4de9-9f40-482111522860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting freesasa\n",
      "  Using cached freesasa-2.2.1-cp311-cp311-linux_x86_64.whl\n",
      "Installing collected packages: freesasa\n",
      "Successfully installed freesasa-2.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install freesasa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0640195c-b761-48d4-bebb-824932ce442d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain E Sequence: AARRCQSQLERANLRPCEQHLMQKIQRSQHQERCCNELNEFENNQRCMCEALQQIMENQSDRLQGRQQEQQFKRELRNLPQQCGLRAPQRCDLDVXXXXXXXXXXXX\n"
     ]
    }
   ],
   "source": [
    "from Bio import PDB\n",
    "from Bio.SeqUtils import seq1\n",
    "import freesasa\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.cluster.hierarchy import fcluster, linkage\n",
    "import csv\n",
    "\n",
    "# Load the structure using BioPython's PDBParser\n",
    "pdb_parser = PDB.PDBParser(QUIET=True)  # QUIET mode to suppress warnings\n",
    "structure = pdb_parser.get_structure(\"structure\", \"./8db4.pdb\")\n",
    "\n",
    "# Specify the chain of interest (e.g., Chain E)\n",
    "chain_id = \"E\"\n",
    "\n",
    "# Extract just the chain of interest from the structure\n",
    "chain_structure = None\n",
    "for model in structure:\n",
    "    chain_structure = model[chain_id]\n",
    "    break  # Exit after extracting the first model (if multiple models exist)\n",
    "\n",
    "# Write a temporary PDB file containing only the selected chain\n",
    "with open(\"temp_chain.pdb\", \"w\") as temp_pdb:\n",
    "    io = PDB.PDBIO()\n",
    "    io.set_structure(chain_structure)\n",
    "    io.save(temp_pdb)\n",
    "\n",
    "# Initialize FreeSASA structure for the specific chain\n",
    "freesasa_structure = freesasa.Structure(\"temp_chain.pdb\")\n",
    "\n",
    "# Run FreeSASA to calculate ASA for each atom\n",
    "result = freesasa.calc(freesasa_structure)\n",
    "\n",
    "# Max ASA values for RSA calculation (adjusted per residue type)\n",
    "max_asa = {\n",
    "    'A': 113, 'R': 241, 'N': 158, 'D': 151, 'C': 140, 'Q': 189, 'E': 183,\n",
    "    'G': 85,  'H': 194, 'I': 182, 'L': 180, 'K': 211, 'M': 204, 'F': 218,\n",
    "    'P': 143, 'S': 122, 'T': 146, 'W': 259, 'Y': 229, 'V': 160\n",
    "}\n",
    "\n",
    "# Function to check for N-glycosylation motif (N-X-S/T)\n",
    "def is_nglycosylated(seq, pos):\n",
    "    if pos + 2 < len(seq) and seq[pos] == 'N':\n",
    "        if seq[pos + 2] in ['S', 'T'] and seq[pos + 1] != 'P':\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "# Prepare CSV output for residue-level data\n",
    "with open('asa_rsa_output.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Residue\", \"ASA\", \"RSA\", \"N-Glycosylation\"])\n",
    "\n",
    "    # FreeSASA iterates over atoms, not residues, so we have to match atoms\n",
    "    atom_idx = 0  # Keep track of FreeSASA atom index\n",
    "\n",
    "    # Get the sequence of residues for N-glycosylation check\n",
    "    chain_sequence = [seq1(res.resname) for res in chain_structure.get_residues()]\n",
    "    print(\"Chain E Sequence:\", \"\".join(chain_sequence))  # Print sequence for debugging\n",
    "\n",
    "    # Extract residue information and calculate ASA, RSA, and N-glycosylation\n",
    "    residue_coords = []  # For storing C-alpha coordinates\n",
    "    rsa_values = []  # For storing RSA values to calculate averages later\n",
    "    for i, residue in enumerate(chain_structure.get_residues()):\n",
    "        try:\n",
    "            # Filter out non-protein residues (e.g., metals, water)\n",
    "            if residue.id[0] != ' ':\n",
    "                continue\n",
    "\n",
    "            res_id = residue.id[1]  # Residue position in the chain\n",
    "            amino = residue.resname  # 3-letter amino acid code\n",
    "            amino_one_letter = seq1(amino)  # Convert to 1-letter code\n",
    "\n",
    "            # Initialize ASA for the entire residue\n",
    "            residue_asa = 0.0\n",
    "\n",
    "            # Iterate over atoms in the residue to sum up their ASA values\n",
    "            for atom in residue:\n",
    "                residue_asa += result.atomArea(atom_idx)\n",
    "                atom_idx += 1  # Move to the next atom\n",
    "\n",
    "            # Calculate RSA (Relative Solvent Accessibility)\n",
    "            rsa = residue_asa / max_asa.get(amino_one_letter, 1)\n",
    "            rsa_values.append(rsa)\n",
    "\n",
    "            # Check if the residue is N-glycosylated and ensure index is valid\n",
    "            n_glycosylation = is_nglycosylated(chain_sequence, i) if i + 2 < len(chain_sequence) else 0\n",
    "\n",
    "            # Create the \"Residue\" field as position:amino\n",
    "            residue_field = f\"{res_id}:{amino_one_letter}\"\n",
    "\n",
    "            # Write to CSV (position:amino, ASA, RSA, N-Glycosylation)\n",
    "            writer.writerow([residue_field, residue_asa, rsa, n_glycosylation])\n",
    "\n",
    "            # Store residue information for clustering\n",
    "            if residue.has_id(\"CA\"):\n",
    "                ca_atom = residue[\"CA\"]\n",
    "                coord = ca_atom.get_coord()\n",
    "                residue_coords.append((res_id, amino_one_letter, coord))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing residue {residue}: {e}\")\n",
    "\n",
    "# Clustering based on 3D proximity\n",
    "# Extract coordinates for clustering\n",
    "positions = np.array([coord[2] for coord in residue_coords])\n",
    "\n",
    "# Calculate pairwise distances between residues based on their Cα coordinates\n",
    "distance_matrix = pdist(positions)  # Use pdist directly, no need for squareform\n",
    "\n",
    "# Cluster residues using a hierarchical clustering approach with 8 Å threshold\n",
    "linkage_matrix = linkage(distance_matrix, method='complete')\n",
    "distance_threshold = 8.0  # Threshold in Å for clustering\n",
    "cluster_labels = fcluster(linkage_matrix, t=distance_threshold, criterion='distance')\n",
    "\n",
    "# Create residue clusters with 1-letter amino acid representation\n",
    "clusters = {}\n",
    "for idx, cluster_id in enumerate(cluster_labels):\n",
    "    if cluster_id not in clusters:\n",
    "        clusters[cluster_id] = {\n",
    "            \"residues\": [],\n",
    "            \"rsa_values\": []\n",
    "        }\n",
    "    res_id, amino_one_letter = residue_coords[idx][0], residue_coords[idx][1]\n",
    "    clusters[cluster_id][\"residues\"].append(f\"{res_id}:{amino_one_letter}\")\n",
    "    clusters[cluster_id][\"rsa_values\"].append(rsa_values[idx])\n",
    "\n",
    "# Write clusters to a new CSV file for residue clusters with average RSA\n",
    "with open('residue_clusters.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Residue_Cluster\", \"Average_RSA\"])\n",
    "\n",
    "    for cluster in clusters.values():\n",
    "        avg_rsa = sum(cluster[\"rsa_values\"]) / len(cluster[\"rsa_values\"]) if cluster[\"rsa_values\"] else 0\n",
    "        writer.writerow([\";\".join(cluster[\"residues\"]), avg_rsa])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "169220a6-f38b-4b07-aa71-7ee0407e1472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hydrophilicity scale (Hopp-Woods scale)\n",
    "hydrophilicity_scale = {\n",
    "    'A': -0.5, 'R': 3.0, 'N': 0.2, 'D': 3.0, 'C': -1.0,\n",
    "    'Q': 0.2,  'E': 3.0, 'G': 0.0, 'H': -0.5, 'I': -1.8,\n",
    "    'L': -1.8, 'K': 3.0, 'M': -1.3, 'F': -2.5, 'P': 0.0,\n",
    "    'S': 0.3,  'T': -0.4, 'W': -3.4, 'Y': -2.3, 'V': -1.5\n",
    "}\n",
    "\n",
    "# Step 1: Update 'asa_rsa_output.csv' with hydrophilicity column\n",
    "# Re-open the existing CSV and add a hydrophilicity column without duplicating columns\n",
    "with open('asa_rsa_output.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    header = next(reader)  # Skip the header row\n",
    "    rows = list(reader)\n",
    "\n",
    "# Check if the header already contains \"Hydrophilicity\"\n",
    "if \"Hydrophilicity\" not in header:\n",
    "    header.append(\"Hydrophilicity\")\n",
    "\n",
    "# Calculate and add hydrophilicity values for each row\n",
    "for row in rows:\n",
    "    try:\n",
    "        residue_info = row[0]  # Format is \"position:amino\"\n",
    "        position, amino_one_letter = residue_info.split(':')\n",
    "        # Assign hydrophilicity based on the amino acid using Hopp-Woods scale\n",
    "        hydrophilicity = hydrophilicity_scale.get(amino_one_letter, 0)\n",
    "        # If the row already has the hydrophilicity column, update it, else append\n",
    "        if len(row) < len(header):\n",
    "            row.append(hydrophilicity)\n",
    "        else:\n",
    "            row[header.index(\"Hydrophilicity\")] = hydrophilicity\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing row {row}: {e}\")\n",
    "\n",
    "# Write the updated data back to 'asa_rsa_output.csv'\n",
    "with open('asa_rsa_output.csv', mode='w', newline='') as outfile:\n",
    "    writer = csv.writer(outfile)\n",
    "    writer.writerow(header)  # Write the updated header\n",
    "    writer.writerows(rows)  # Write all rows with updated hydrophilicity values\n",
    "\n",
    "# Step 2: Load residue hydrophilicity data from the updated 'asa_rsa_output.csv'\n",
    "residue_hydrophilicity = {}\n",
    "\n",
    "# Read the updated residue-level data including hydrophilicity\n",
    "with open('asa_rsa_output.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    header = next(reader)  # Skip the header row\n",
    "    for row in reader:\n",
    "        residue_info = row[0]  # Format is \"position:amino\"\n",
    "        position, amino = residue_info.split(':')\n",
    "        position = int(position)  # Convert position to an integer for easier lookup\n",
    "        hydrophilicity = float(row[header.index(\"Hydrophilicity\")])\n",
    "        residue_hydrophilicity[position] = hydrophilicity\n",
    "\n",
    "# Step 3: Update 'residue_clusters.csv' with average hydrophilicity column\n",
    "clusters_with_hydrophilicity = []\n",
    "\n",
    "with open('residue_clusters.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    header = next(reader)  # Skip the header row\n",
    "\n",
    "    # Ensure \"Average_Hydrophilicity\" is in the header\n",
    "    if \"Average_Hydrophilicity\" not in header:\n",
    "        header.append(\"Average_Hydrophilicity\")\n",
    "\n",
    "    for row in reader:\n",
    "        residues = row[0].split(';')  # Residues are in the format \"position:amino\"\n",
    "\n",
    "        # Calculate the average hydrophilicity for each cluster\n",
    "        total_hydrophilicity = 0\n",
    "        residue_count = 0\n",
    "        for residue in residues:\n",
    "            position, amino = residue.split(':')\n",
    "            position = int(position)\n",
    "            if position in residue_hydrophilicity:\n",
    "                total_hydrophilicity += residue_hydrophilicity[position]\n",
    "                residue_count += 1\n",
    "\n",
    "        # Compute the average hydrophilicity for the cluster\n",
    "        avg_hydrophilicity = total_hydrophilicity / residue_count if residue_count > 0 else 0\n",
    "\n",
    "        # Update row with the average hydrophilicity\n",
    "        if len(row) < len(header):  # If only the cluster information is present\n",
    "            row.append(avg_hydrophilicity)\n",
    "        else:\n",
    "            row[header.index(\"Average_Hydrophilicity\")] = avg_hydrophilicity\n",
    "        clusters_with_hydrophilicity.append(row)\n",
    "\n",
    "# Write the updated cluster data back to 'residue_clusters.csv'\n",
    "with open('residue_clusters.csv', mode='w', newline='') as outfile:\n",
    "    writer = csv.writer(outfile)\n",
    "    writer.writerow(header)  # Write the updated header\n",
    "    writer.writerows(clusters_with_hydrophilicity)  # Write all updated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e86809b9-2ab6-4e75-8f5f-f26a3ac4a4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_factors = []\n",
    "for residue in chain_structure.get_residues():\n",
    "    if residue.id[0] == ' ':\n",
    "        # Calculate the average B-factor for the residue\n",
    "        avg_b_factor = sum(atom.get_bfactor() for atom in residue) / len(residue)\n",
    "        b_factors.append(avg_b_factor)\n",
    "\n",
    "# Step 2: Update 'asa_rsa_output.csv' to add or update B-factor column\n",
    "with open('asa_rsa_output.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    header = next(reader)\n",
    "    rows = list(reader)\n",
    "\n",
    "# Check if the header already contains \"B-Factor\"\n",
    "if \"B-Factor\" not in header:\n",
    "    header.append(\"B-Factor\")\n",
    "\n",
    "# Add or update B-factor values for each row\n",
    "for i, row in enumerate(rows):\n",
    "    try:\n",
    "        b_factor = b_factors[i]\n",
    "        # If the row already has the B-factor column, update it; otherwise, append\n",
    "        if len(row) < len(header):\n",
    "            row.append(b_factor)\n",
    "        else:\n",
    "            row[header.index(\"B-Factor\")] = b_factor  # Use index of \"B-Factor\" in header\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing row {row}: {e}\")\n",
    "\n",
    "# Write the updated data back to 'asa_rsa_output.csv'\n",
    "with open('asa_rsa_output.csv', mode='w', newline='') as outfile:\n",
    "    writer = csv.writer(outfile)\n",
    "    writer.writerow(header)  # Write the updated header\n",
    "    writer.writerows(rows)  # Write all rows with updated B-factor values\n",
    "\n",
    "# Step 3: Load residue B-factor data from 'asa_rsa_output.csv'\n",
    "residue_data = {}\n",
    "\n",
    "# Read the updated residue-level data including B-factor\n",
    "with open('asa_rsa_output.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    header = next(reader)\n",
    "    for row in reader:\n",
    "        residue_info = row[0]  # Format is \"position:amino\"\n",
    "        position, amino = residue_info.split(':')\n",
    "        position = int(position)  # Convert position to an integer for easier lookup\n",
    "        b_factor = float(row[header.index(\"B-Factor\")])  # Get B-factor value from header index\n",
    "        hydrophilicity = float(row[header.index(\"Hydrophilicity\")])  # Get hydrophilicity value from header index if exists\n",
    "        residue_data[position] = {\"b_factor\": b_factor, \"hydrophilicity\": hydrophilicity}\n",
    "\n",
    "# Step 4: Update 'residue_clusters.csv' with average hydrophilicity and B-factor columns\n",
    "clusters_with_data = []\n",
    "\n",
    "with open('residue_clusters.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    header = next(reader)\n",
    "\n",
    "    # Ensure correct header columns are present\n",
    "    if \"Average_Hydrophilicity\" not in header:\n",
    "        header.append(\"Average_Hydrophilicity\")\n",
    "    if \"Average_B-Factor\" not in header:\n",
    "        header.append(\"Average_B-Factor\")\n",
    "\n",
    "    for row in reader:\n",
    "        residues = row[0].split(';')  # Residues are in the format \"position:amino\"\n",
    "\n",
    "        # Calculate the average hydrophilicity and B-factor for each cluster\n",
    "        total_hydrophilicity = 0\n",
    "        total_b_factor = 0\n",
    "        residue_count = 0\n",
    "\n",
    "        for residue in residues:\n",
    "            position, amino = residue.split(':')\n",
    "            position = int(position)\n",
    "            if position in residue_data:\n",
    "                total_hydrophilicity += residue_data[position][\"hydrophilicity\"]\n",
    "                total_b_factor += residue_data[position][\"b_factor\"]\n",
    "                residue_count += 1\n",
    "\n",
    "        # Compute the average values for the cluster\n",
    "        avg_hydrophilicity = total_hydrophilicity / residue_count if residue_count > 0 else 0\n",
    "        avg_b_factor = total_b_factor / residue_count if residue_count > 0 else 0\n",
    "\n",
    "        # Ensure the row has enough columns to add or update the data\n",
    "        updated_row = [row[0]]  # Start with the cluster information\n",
    "\n",
    "        # If there are existing columns for hydrophilicity and B-factor, update them\n",
    "        if len(row) > 1:\n",
    "            updated_row.extend([row[1], avg_hydrophilicity, avg_b_factor])\n",
    "        else:\n",
    "            # Append the calculated average values for hydrophilicity and B-factor\n",
    "            updated_row.extend([avg_hydrophilicity, avg_b_factor])\n",
    "\n",
    "        clusters_with_data.append(updated_row)\n",
    "\n",
    "# Write the updated cluster data back to 'residue_clusters.csv'\n",
    "with open('residue_clusters.csv', mode='w', newline='') as outfile:\n",
    "    writer = csv.writer(outfile)\n",
    "    writer.writerow(header)  # Write the updated header\n",
    "    writer.writerows(clusters_with_data)  # Write all updated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e922f41b-2582-46ec-8542-3d4f96622906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charge scale for residues (basic, acidic, or neutral)\n",
    "charge_scale = {\n",
    "    'A': 0, 'R': 1, 'N': 0, 'D': -1, 'C': 0,\n",
    "    'Q': 0, 'E': -1, 'G': 0, 'H': 1, 'I': 0,\n",
    "    'L': 0, 'K': 1, 'M': 0, 'F': 0, 'P': 0,\n",
    "    'S': 0, 'T': 0, 'W': 0, 'Y': 0, 'V': 0\n",
    "}\n",
    "\n",
    "# Update the CSV to add Charge column\n",
    "with open('asa_rsa_output.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    header = next(reader)\n",
    "    rows = list(reader)\n",
    "\n",
    "# Check if the header already contains \"Charge\"\n",
    "if \"Charge\" not in header:\n",
    "    header.append(\"Charge\")\n",
    "\n",
    "# Add or update charge values for each row\n",
    "for row in rows:\n",
    "    try:\n",
    "        residue_info = row[0]  # Format is \"position:amino\"\n",
    "        _, amino = residue_info.split(':')\n",
    "        # Assign charge based on the amino acid\n",
    "        charge = charge_scale.get(amino, 0)\n",
    "        # If the row already has the charge column, update it, else append\n",
    "        if len(row) < len(header):\n",
    "            row.append(charge)\n",
    "        else:\n",
    "            row[header.index(\"Charge\")] = charge\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing row {row}: {e}\")\n",
    "\n",
    "# Write the updated data back to 'asa_rsa_output.csv'\n",
    "with open('asa_rsa_output.csv', mode='w', newline='') as outfile:\n",
    "    writer = csv.writer(outfile)\n",
    "    writer.writerow(header)  # Write the updated header\n",
    "    writer.writerows(rows)  # Write all rows with updated charge values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
