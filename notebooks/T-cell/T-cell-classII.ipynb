{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d527a19-ed65-420b-b10b-a060dd5259fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82c1a45c-7623-4adf-9257-7ac77ad29548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_protein_sequence_classII(protein_sequence, min_length=13, max_length=25):\n",
    "    \"\"\"\n",
    "    Splits a protein sequence into peptides suitable for Class II MHC binding, generating most possible overlapping peptides\n",
    "    between the minimum and maximum length specified.\n",
    "\n",
    "    Args:\n",
    "        protein_sequence (str): The amino acid sequence of the protein.\n",
    "        min_length (int): The minimum length of each peptide (default is 13).\n",
    "        max_length (int): The maximum length of each peptide (default is 25).\n",
    "\n",
    "    Returns:\n",
    "        list: A list of peptide sequences.\n",
    "    \"\"\"\n",
    "    peptides = []\n",
    "    for length in range(min_length, max_length + 1):\n",
    "        peptides.extend([protein_sequence[i:i+length] \n",
    "                         for i in range(0, len(protein_sequence) - length + 1)])\n",
    "    return peptides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d02b07-4d27-48bf-9f57-233bbb965694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "protein_sequence = \"MTEYKLVVVGAGGVGKSALTIQLIQNHFVDEYDPTIEDSYRKQVVIDGETCLLDILDTAG\"\n",
    "\n",
    "# Class II peptides\n",
    "classII_peptides = split_protein_sequence_classII(protein_sequence)\n",
    "print(\"Class II Peptides:\", classII_peptides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6bec27ef-84e5-4c9b-9aa2-5a6dd51879f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from itertools import product\n",
    "\n",
    "IEDB_API_URL_CLASSII = \"http://tools-cluster-interface.iedb.org/tools_api/mhcii/\"\n",
    "\n",
    "\n",
    "def run_netmhciipan_binding_affinity_classII(peptides, hla_alleles):\n",
    "    \"\"\"\n",
    "    Uses IEDB API to generate binding affinity for each peptide and HLA interaction for Class II MHC.\n",
    "\n",
    "    Args:\n",
    "        peptides (list): A list of peptide sequences.\n",
    "        hla_alleles (list): A list of HLA alleles for which to make predictions.\n",
    "\n",
    "    Returns:\n",
    "        dict: The binding affinity results for each peptide and HLA allele combination.\n",
    "    \"\"\"\n",
    "    # Prepare sequence text in FASTA format and escape special characters\n",
    "    sequence_text = \"\".join([f\">peptide{i}\\n{peptide}\\n\" for i, peptide in enumerate(peptides)])\n",
    "    hla_alleles_str = \",\".join(hla_alleles)\n",
    "\n",
    "    # Prepare the payload for the POST request\n",
    "    payload = {\n",
    "        \"method\": \"netmhciipan-4.1\",\n",
    "        \"sequence_text\": sequence_text,\n",
    "        \"allele\": hla_alleles_str,\n",
    "        \"length\": \"asis\"\n",
    "    }\n",
    "\n",
    "    # Make the POST request to IEDB API\n",
    "    try:\n",
    "        response = requests.post(IEDB_API_URL_CLASSII, data=payload)\n",
    "        response.raise_for_status()\n",
    "        return {\"results\": response.text}\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return {\"error\": str(e)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0dabcbeb-8ffc-44fb-b235-dfbb68f558ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class II Results: {'results': 'allele\\tseq_num\\tstart\\tend\\tlength\\tcore_peptide\\tpeptide\\tic50\\trank\\nHLA-DQA1*05:01/DQB1*02:01\\t2\\t1\\t23\\t23\\tYDPTIEDSY\\tIQLIQNHFVDEYDPTIEDSYRKQ\\t369.97\\t3.7\\nHLA-DRB1*01:01\\t2\\t1\\t23\\t23\\tFVDEYDPTI\\tIQLIQNHFVDEYDPTIEDSYRKQ\\t1370.67\\t84.0\\nHLA-DQA1*05:01/DQB1*02:01\\t1\\t1\\t15\\t15\\tIEDSYRKQV\\tDPTIEDSYRKQVVID\\t10064.76\\t86.0\\nHLA-DRB1*01:01\\t1\\t1\\t15\\t15\\tIEDSYRKQV\\tDPTIEDSYRKQVVID\\t3987.26\\t91.0\\n'}\n"
     ]
    }
   ],
   "source": [
    "# Example usage for Class II\n",
    "peptides_classII = [\"DPTIEDSYRKQVVID\", \"IQLIQNHFVDEYDPTIEDSYRKQ\"]\n",
    "hla_alleles_classII = [\"HLA-DRB1*01:01\", \"HLA-DQA1*05:01/DQB1*02:01\"]\n",
    "result_classII = run_netmhciipan_binding_affinity_classII(peptides_classII, hla_alleles_classII)\n",
    "print(\"Class II Results:\", result_classII)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "985e9330-878d-4922-bd76-1376bc8bf080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Class II Results:\n",
      "                      allele  seq_num  start  end  length core_peptide  \\\n",
      "0  HLA-DQA1*05:01/DQB1*02:01        2      1   23      23    YDPTIEDSY   \n",
      "1             HLA-DRB1*01:01        2      1   23      23    FVDEYDPTI   \n",
      "2  HLA-DQA1*05:01/DQB1*02:01        1      1   15      15    IEDSYRKQV   \n",
      "3             HLA-DRB1*01:01        1      1   15      15    IEDSYRKQV   \n",
      "\n",
      "                   peptide      ic50  rank  \n",
      "0  IQLIQNHFVDEYDPTIEDSYRKQ    369.97   3.7  \n",
      "1  IQLIQNHFVDEYDPTIEDSYRKQ   1370.67  84.0  \n",
      "2          DPTIEDSYRKQVVID  10064.76  86.0  \n",
      "3          DPTIEDSYRKQVVID   3987.26  91.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "def process_classII_results(results_text):\n",
    "    \"\"\"\n",
    "    Processes the Class II results returned by the IEDB API.\n",
    "\n",
    "    Args:\n",
    "        results_text (str): The raw results text returned by the API.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A pandas DataFrame with processed results.\n",
    "    \"\"\"\n",
    "    # Use StringIO to convert the string into a file-like object\n",
    "    results_io = StringIO(results_text)\n",
    "    # Read the results into a pandas DataFrame\n",
    "    df = pd.read_csv(results_io, sep=\"\\t\")\n",
    "    return df\n",
    "\n",
    "# Process the results for Class II\n",
    "if \"results\" in result_classII:\n",
    "    df_classII_results = process_classII_results(result_classII[\"results\"])\n",
    "    print(\"Processed Class II Results:\")\n",
    "    print(df_classII_results)\n",
    "else:\n",
    "    print(\"Error in Class II Results:\", result_classII[\"error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0820b7b8-982a-4a4d-8512-bb514d00de25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 36 Class II peptides.\n",
      "Initial CSV file 'classII_peptides.csv' created with 36 peptides.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 183\u001b[0m\n\u001b[1;32m    180\u001b[0m hla_alleles_classII \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHLA-DRB1*01:01\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHLA-DQA1*05:01/DQB1*02:01\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m# Step 4: Run NetMHCIIpan binding affinity predictions for Class II\u001b[39;00m\n\u001b[0;32m--> 183\u001b[0m result_classII \u001b[38;5;241m=\u001b[39m \u001b[43mrun_netmhciipan_binding_affinity_classII\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclassII_peptides\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhla_alleles_classII\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m result_classII:\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuccessfully retrieved Class II binding affinity results.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 86\u001b[0m, in \u001b[0;36mrun_netmhciipan_binding_affinity_classII\u001b[0;34m(peptides, hla_alleles)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# Make the POST request to IEDB API\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 86\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mIEDB_API_URL_CLASSII\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m\"\u001b[39m: response\u001b[38;5;241m.\u001b[39mtext}\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/urllib3/connectionpool.py:715\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    714\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 715\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[1;32m    729\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/urllib3/connectionpool.py:467\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    462\u001b[0m             httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    463\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    464\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    465\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    466\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 467\u001b[0m             \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/urllib3/connectionpool.py:462\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 462\u001b[0m         httplib_response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    464\u001b[0m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    465\u001b[0m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    466\u001b[0m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    467\u001b[0m         six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/http/client.py:1395\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1393\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1394\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1395\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1396\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1397\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/http/client.py:325\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 325\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/http/client.py:286\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 286\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    288\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# Assuming the notebook is running from the T-cell directory, use the current directory\n",
    "IEDB_API_URL_CLASSII = \"http://tools-cluster-interface.iedb.org/tools_api/mhcii/\"\n",
    "CSV_FILE_CLASSII = \"classII_peptides.csv\"\n",
    "\n",
    "# Step 1: Split Protein Sequence into Peptides\n",
    "def split_protein_sequence_classII(protein_sequence, min_length=13, max_length=25):\n",
    "    \"\"\"\n",
    "    Splits a protein sequence into peptides suitable for Class II MHC binding, generating most possible overlapping peptides\n",
    "    between the minimum and maximum length specified.\n",
    "\n",
    "    Args:\n",
    "        protein_sequence (str): The amino acid sequence of the protein.\n",
    "        min_length (int): The minimum length of each peptide (default is 13).\n",
    "        max_length (int): The maximum length of each peptide (default is 25).\n",
    "\n",
    "    Returns:\n",
    "        list: A list of peptide sequences.\n",
    "    \"\"\"\n",
    "    peptides = []\n",
    "    for length in range(min_length, max_length + 1):\n",
    "        peptides.extend([protein_sequence[i:i+length] \n",
    "                         for i in range(0, len(protein_sequence) - length + 1)])\n",
    "    return peptides\n",
    "\n",
    "# Step 2: Create Initial CSV File\n",
    "def create_initial_csv_classII(peptides, csv_file=CSV_FILE_CLASSII):\n",
    "    \"\"\"\n",
    "    Creates an initial CSV file with peptide sequences for Class II.\n",
    "\n",
    "    Args:\n",
    "        peptides (list): A list of peptide sequences.\n",
    "        csv_file (str): The CSV file path to create.\n",
    "    \"\"\"\n",
    "    columns = [\n",
    "        \"Peptide_Sequence\", \n",
    "        \"ClassII_TCR_Recognition\", \n",
    "        \"ClassII_MHC_Binding_Affinity\",\n",
    "        \"ClassII_pMHC_Stability\", \n",
    "        \"Best_Binding_Affinity\", \n",
    "        \"Best_pMHC_Stability\"\n",
    "    ]\n",
    "    initial_df = pd.DataFrame(peptides, columns=[\"Peptide_Sequence\"])\n",
    "    \n",
    "    # Initialize other columns with empty strings and set dtype to 'string'\n",
    "    for col in columns[1:]:\n",
    "        initial_df[col] = \"\"\n",
    "        initial_df[col] = initial_df[col].astype('string')  # Explicitly set dtype\n",
    "    \n",
    "    # Save the DataFrame to CSV with quoting for non-numeric fields\n",
    "    initial_df.to_csv(csv_file, index=False, quoting=csv.QUOTE_NONNUMERIC)\n",
    "    print(f\"Initial CSV file '{csv_file}' created with {len(peptides)} peptides.\")\n",
    "\n",
    "# Step 3: Run NetMHCII Binding Affinity Predictions\n",
    "def run_netmhciipan_binding_affinity_classII(peptides, hla_alleles):\n",
    "    \"\"\"\n",
    "    Uses IEDB API to generate binding affinity for each peptide and HLA interaction for Class II MHC.\n",
    "\n",
    "    Args:\n",
    "        peptides (list): A list of peptide sequences.\n",
    "        hla_alleles (list): A list of HLA alleles for which to make predictions.\n",
    "\n",
    "    Returns:\n",
    "        dict: The binding affinity results for each peptide and HLA allele combination.\n",
    "    \"\"\"\n",
    "    # Prepare sequence text in FASTA format\n",
    "    sequence_text = \"\".join([f\">peptide{i}\\n{peptide}\\n\" for i, peptide in enumerate(peptides)])\n",
    "    hla_alleles_str = \",\".join(hla_alleles)\n",
    "\n",
    "    # Prepare the payload for the POST request\n",
    "    payload = {\n",
    "        \"method\": \"netmhciipan-4.1\",\n",
    "        \"sequence_text\": sequence_text,\n",
    "        \"allele\": hla_alleles_str,\n",
    "        \"length\": \"asis\"\n",
    "    }\n",
    "\n",
    "    # Make the POST request to IEDB API\n",
    "    try:\n",
    "        response = requests.post(IEDB_API_URL_CLASSII, data=payload)\n",
    "        response.raise_for_status()\n",
    "        return {\"results\": response.text}\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# Step 4: Process Class II Results\n",
    "def process_classII_results(results_text):\n",
    "    \"\"\"\n",
    "    Processes the Class II results returned by the IEDB API.\n",
    "\n",
    "    Args:\n",
    "        results_text (str): The raw results text returned by the API.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A pandas DataFrame with processed results.\n",
    "    \"\"\"\n",
    "    # Use StringIO to convert the string into a file-like object\n",
    "    results_io = StringIO(results_text)\n",
    "    # Read the results into a pandas DataFrame\n",
    "    df = pd.read_csv(results_io, sep=\"\\t\")\n",
    "    return df\n",
    "\n",
    "# Step 5: Update CSV with Class II Results\n",
    "def update_csv_with_classII_results(df, csv_file=CSV_FILE_CLASSII):\n",
    "    \"\"\"\n",
    "    Updates the CSV file with Class II MHC binding results.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): A pandas DataFrame with processed results.\n",
    "        csv_file (str): The CSV file path to update.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(csv_file):\n",
    "        raise FileNotFoundError(f\"The CSV file {csv_file} does not exist. Please create it first.\")\n",
    "    \n",
    "    # Read existing CSV with all columns as strings\n",
    "    existing_df = pd.read_csv(csv_file, dtype=str)\n",
    "    \n",
    "    # Iterate through each row in the new results and update the CSV\n",
    "    for _, row in df.iterrows():\n",
    "        peptide = row['peptide']\n",
    "        allele = row['allele']\n",
    "        ic50 = row['ic50']\n",
    "        pMHC_stability = row.get('pMHC_stability', \"\")  # Assuming stability information is included\n",
    "\n",
    "        # Find the existing entry for the peptide\n",
    "        if peptide in existing_df[\"Peptide_Sequence\"].values:\n",
    "            idx = existing_df.index[existing_df[\"Peptide_Sequence\"] == peptide][0]\n",
    "\n",
    "            # Update the ClassII_MHC_Binding_Affinity\n",
    "            affinity_str = f\"{allele}={ic50} nM\"\n",
    "            existing_affinity = existing_df.at[idx, \"ClassII_MHC_Binding_Affinity\"]\n",
    "            if pd.isna(existing_affinity) or existing_affinity == \"\" or existing_affinity is None:\n",
    "                existing_df.at[idx, \"ClassII_MHC_Binding_Affinity\"] = affinity_str\n",
    "            else:\n",
    "                existing_df.at[idx, \"ClassII_MHC_Binding_Affinity\"] = f\"{existing_affinity}|{affinity_str}\"\n",
    "            \n",
    "            # Update the ClassII_pMHC_Stability\n",
    "            if pMHC_stability:\n",
    "                stability_str = f\"{allele}={pMHC_stability} hrs\"\n",
    "                existing_stability = existing_df.at[idx, \"ClassII_pMHC_Stability\"]\n",
    "                if pd.isna(existing_stability) or existing_stability == \"\" or existing_stability is None:\n",
    "                    existing_df.at[idx, \"ClassII_pMHC_Stability\"] = stability_str\n",
    "                else:\n",
    "                    existing_df.at[idx, \"ClassII_pMHC_Stability\"] = f\"{existing_stability}|{stability_str}\"\n",
    "\n",
    "            # Update the Best_Binding_Affinity\n",
    "            existing_affinities = existing_df.at[idx, \"ClassII_MHC_Binding_Affinity\"].split('|')\n",
    "            best_affinity = min(existing_affinities, key=lambda x: float(x.split('=')[1].replace(' nM', '')))\n",
    "            existing_df.at[idx, \"Best_Binding_Affinity\"] = best_affinity\n",
    "\n",
    "            # Update the Best_pMHC_Stability (assuming the best stability is linked to the best affinity)\n",
    "            if pMHC_stability:\n",
    "                stability_info = [stab for stab in existing_df.at[idx, \"ClassII_pMHC_Stability\"].split('|') if stab.startswith(best_affinity.split('=')[0])]\n",
    "                if stability_info:\n",
    "                    existing_df.at[idx, \"Best_pMHC_Stability\"] = stability_info[0]\n",
    "\n",
    "    # Save the updated DataFrame back to CSV\n",
    "    existing_df.to_csv(csv_file, index=False, quoting=csv.QUOTE_NONNUMERIC)\n",
    "    print(f\"CSV file '{csv_file}' has been updated with Class II binding affinity results.\")\n",
    "\n",
    "# Main function for execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    protein_sequence = \"MTEYKLVVVGAGGVGKSALT\"\n",
    "\n",
    "    # Step 1: Split the protein sequence into peptides for Class II\n",
    "    classII_peptides = split_protein_sequence_classII(protein_sequence)\n",
    "    print(f\"Generated {len(classII_peptides)} Class II peptides.\")\n",
    "\n",
    "    # Step 2: Create initial CSV file for Class II\n",
    "    create_initial_csv_classII(classII_peptides)\n",
    "\n",
    "    # Step 3: Define HLA alleles for Class II\n",
    "    hla_alleles_classII = [\"HLA-DRB1*01:01\", \"HLA-DQA1*05:01/DQB1*02:01\"]\n",
    "\n",
    "    # Step 4: Run NetMHCIIpan binding affinity predictions for Class II\n",
    "    result_classII = run_netmhciipan_binding_affinity_classII(classII_peptides, hla_alleles_classII)\n",
    "    if \"results\" in result_classII:\n",
    "        print(\"Successfully retrieved Class II binding affinity results.\")\n",
    "        # Step 5: Process the results\n",
    "        df_classII_results = process_classII_results(result_classII[\"results\"])\n",
    "        print(\"Processed Class II Results:\")\n",
    "        print(df_classII_results.head())\n",
    "        \n",
    "        # Step 6: Update the CSV with results\n",
    "        update_csv_with_classII_results(df_classII_results)\n",
    "        print(f\"CSV file '{CSV_FILE_CLASSII}' has been updated with Class II binding affinity results.\")\n",
    "    else:\n",
    "        print(\"Error in Class II Results:\", result_classII[\"error\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dffea3-1044-4d74-add5-94c7b5b7d438",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
