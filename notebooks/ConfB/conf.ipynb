{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ea7ccee-e2ff-4fb0-9fd7-1d38f63e5b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from esm.utils.structure.protein_chain import ProteinChain\n",
    "from esm.sdk import client\n",
    "from esm.sdk.api import (\n",
    "    ESMProtein,\n",
    "    GenerationConfig,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e483a0c-91ea-4b7c-914c-809651abeff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDB file 3OB4 downloaded successfully to ./pdb_proteins/3OB4.pdb\n",
      "Chain ID: A, Number of residues: 551\n",
      "Chain ID: B, Number of residues: 3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "from Bio.PDB import PDBParser, PDBIO\n",
    "\n",
    "# Function to fetch and save a PDB file from RCSB\n",
    "\n",
    "def fetch_pdb(pdb_id, output_dir):\n",
    "    url = f\"https://files.rcsb.org/download/{pdb_id}.pdb\"\n",
    "    output_path = os.path.join(output_dir, f\"{pdb_id}.pdb\")\n",
    "    try:\n",
    "        urllib.request.urlretrieve(url, output_path)\n",
    "        print(f\"PDB file {pdb_id} downloaded successfully to {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download PDB file {pdb_id}: {e}\")\n",
    "    return output_path\n",
    "\n",
    "# Specify the PDB ID and output directory\n",
    "pdb_id = \"3OB4\"\n",
    "output_dir = \"./pdb_proteins/\"\n",
    "\n",
    "# Fetch the PDB file\n",
    "pdb_file_path = fetch_pdb(pdb_id, output_dir)\n",
    "\n",
    "# Load the structure using Bio.PDB\n",
    "pdb_parser = PDBParser(QUIET=True)\n",
    "structure = pdb_parser.get_structure(\"structure\", pdb_file_path)\n",
    "\n",
    "# Iterate over the chains in the structure\n",
    "for model in structure:\n",
    "    for chain in model:\n",
    "        print(f\"Chain ID: {chain.id}, Number of residues: {len(chain)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc6ac490-0ee7-45a5-98e2-7279b9711dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KIEEGKLVIWINGDKGYNGLAEVGKKFEKDTGIKVTVEHPDKLEEKFPQVAATGDGPDIIFWAHDRFGGYAQSGLLAEITPAAAFQDKLYPFTWDAVRYNGKLIAYPIAVEALSLIYNKDLLPNPPKTWEEIPALDKELKAKGKSALMFNLQEPYFTWPLIAADGGYAFKYAAGKYDIKDVGVDNAGAKAGLTFLVDLIKNKHMNADTDYSIAEAAFNKGETAMTINGPWAWSNIDTSAVNYGVTVLPTFKGQPSKPFVGVLSAGINAASPNKELAKEFLENYLLTDEGLEAVNKDKPLGAVALKSYEEELAKDPRIAATMENAQKGEIMPNIPQMSAFWYAVRTAVINAASGRQTVDAALAAAQTNAAARRCQSQLERANLRPCEQHLMQKIQRDEDSRDPYSPSQDPHQERCCNELNEFENNQRCMCEALQQIMENQSDRLQGRQQEQQFKRELRNLPQQCGLRAPQRCDLD\n"
     ]
    }
   ],
   "source": [
    "chain_id = \"A\"  # Chain ID corresponding to Ara h 2 in the PDB structure\n",
    "arah2_chain = ProteinChain.from_pdb(pdb_file_path, chain_id)\n",
    "# Alternatively, we could have used ProteinChain.from_pdb() to load a protein structure from a local PDB file\n",
    "\n",
    "print(arah2_chain.sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52d6703f-b46b-4de9-9f40-482111522860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting freesasa\n",
      "  Using cached freesasa-2.2.1-cp311-cp311-linux_x86_64.whl\n",
      "Installing collected packages: freesasa\n",
      "Successfully installed freesasa-2.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install freesasa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0640195c-b761-48d4-bebb-824932ce442d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain A Sequence: KIEEGKLVIWINGDKGYNGLAEVGKKFEKDTGIKVTVEHPDKLEEKFPQVAATGDGPDIIFWAHDRFGGYAQSGLLAEITPAAAFQDKLYPFTWDAVRYNGKLIAYPIAVEALSLIYNKDLLPNPPKTWEEIPALDKELKAKGKSALMFNLQEPYFTWPLIAADGGYAFKYAAGKYDIKDVGVDNAGAKAGLTFLVDLIKNKHMNADTDYSIAEAAFNKGETAMTINGPWAWSNIDTSAVNYGVTVLPTFKGQPSKPFVGVLSAGINAASPNKELAKEFLENYLLTDEGLEAVNKDKPLGAVALKSYEEELAKDPRIAATMENAQKGEIMPNIPQMSAFWYAVRTAVINAASGRQTVDAALAAAQTNAAARRCQSQLERANLRPCEQHLMQKIQRDEDSRDPYSPSQDPHQERCCNELNEFENNQRCMCEALQQIMENQSDRLQGRQQEQQFKRELRNLPQQCGLRAPQRCDLDXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n"
     ]
    }
   ],
   "source": [
    "from Bio.SeqUtils import seq1\n",
    "import freesasa\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.cluster.hierarchy import fcluster, linkage\n",
    "import csv\n",
    "\n",
    "# Extract just the chain of interest from the structure\n",
    "chain_structure = None\n",
    "for model in structure:\n",
    "    chain_structure = model[chain_id]\n",
    "    break  # Exit after extracting the first model (if multiple models exist)\n",
    "\n",
    "# Write a temporary PDB file containing only the selected chain\n",
    "with open(\"temp_chain.pdb\", \"w\") as temp_pdb:\n",
    "    io = PDBIO()\n",
    "    io.set_structure(chain_structure)\n",
    "    io.save(temp_pdb)\n",
    "\n",
    "# Initialize FreeSASA structure for the specific chain\n",
    "freesasa_structure = freesasa.Structure(\"temp_chain.pdb\")\n",
    "\n",
    "# Run FreeSASA to calculate ASA for each atom\n",
    "result = freesasa.calc(freesasa_structure)\n",
    "\n",
    "# Max ASA values for RSA calculation (adjusted per residue type)\n",
    "max_asa = {\n",
    "    'A': 113, 'R': 241, 'N': 158, 'D': 151, 'C': 140, 'Q': 189, 'E': 183,\n",
    "    'G': 85,  'H': 194, 'I': 182, 'L': 180, 'K': 211, 'M': 204, 'F': 218,\n",
    "    'P': 143, 'S': 122, 'T': 146, 'W': 259, 'Y': 229, 'V': 160\n",
    "}\n",
    "\n",
    "# Function to check for N-glycosylation motif (N-X-S/T)\n",
    "def is_nglycosylated(seq, pos):\n",
    "    if pos + 2 < len(seq) and seq[pos] == 'N':\n",
    "        if seq[pos + 2] in ['S', 'T'] and seq[pos + 1] != 'P':\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "# Prepare CSV output for residue-level data\n",
    "with open('asa_rsa_output.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Residue\", \"ASA\", \"RSA\", \"N-Glycosylation\"])\n",
    "\n",
    "    # FreeSASA iterates over atoms, not residues, so we have to match atoms\n",
    "    atom_idx = 0  # Keep track of FreeSASA atom index\n",
    "\n",
    "    # Get the sequence of residues for N-glycosylation check\n",
    "    chain_sequence = [seq1(res.resname) for res in chain_structure.get_residues()]\n",
    "    print(\"Chain A Sequence:\", \"\".join(chain_sequence))  # Print sequence for debugging\n",
    "\n",
    "    # Extract residue information and calculate ASA, RSA, and N-glycosylation\n",
    "    residue_coords = []  # For storing C-alpha coordinates\n",
    "    rsa_values = []  # For storing RSA values to calculate averages later\n",
    "    for i, residue in enumerate(chain_structure.get_residues()):\n",
    "        try:\n",
    "            # Filter out non-protein residues (e.g., metals, water)\n",
    "            if residue.id[0] != ' ':\n",
    "                continue\n",
    "\n",
    "            res_id = residue.id[1]  # Residue position in the chain\n",
    "            amino = residue.resname  # 3-letter amino acid code\n",
    "            amino_one_letter = seq1(amino)  # Convert to 1-letter code\n",
    "\n",
    "            # Initialize ASA for the entire residue\n",
    "            residue_asa = 0.0\n",
    "\n",
    "            # Iterate over atoms in the residue to sum up their ASA values\n",
    "            for atom in residue:\n",
    "                residue_asa += result.atomArea(atom_idx)\n",
    "                atom_idx += 1  # Move to the next atom\n",
    "\n",
    "            # Calculate RSA (Relative Solvent Accessibility)\n",
    "            rsa = residue_asa / max_asa.get(amino_one_letter, 1)\n",
    "            rsa_values.append(rsa)\n",
    "\n",
    "            # Check if the residue is N-glycosylated and ensure index is valid\n",
    "            n_glycosylation = is_nglycosylated(chain_sequence, i) if i + 2 < len(chain_sequence) else 0\n",
    "\n",
    "            # Create the \"Residue\" field as position:amino\n",
    "            residue_field = f\"{res_id}:{amino_one_letter}\"\n",
    "\n",
    "            # Write to CSV (position:amino, ASA, RSA, N-Glycosylation)\n",
    "            writer.writerow([residue_field, residue_asa, rsa, n_glycosylation])\n",
    "\n",
    "            # Store residue information for clustering\n",
    "            if residue.has_id(\"CA\"):\n",
    "                ca_atom = residue[\"CA\"]\n",
    "                coord = ca_atom.get_coord()\n",
    "                residue_coords.append((res_id, amino_one_letter, coord))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing residue {residue}: {e}\")\n",
    "\n",
    "# Clustering based on 3D proximity\n",
    "# Extract coordinates for clustering\n",
    "positions = np.array([coord[2] for coord in residue_coords])\n",
    "\n",
    "# Calculate pairwise distances between residues based on their Cα coordinates\n",
    "distance_matrix = pdist(positions)  # Use pdist directly, no need for squareform\n",
    "\n",
    "# Cluster residues using a hierarchical clustering approach with 8 Å threshold\n",
    "linkage_matrix = linkage(distance_matrix, method='complete')\n",
    "distance_threshold = 8.0  # Threshold in Å for clustering\n",
    "cluster_labels = fcluster(linkage_matrix, t=distance_threshold, criterion='distance')\n",
    "\n",
    "# Create residue clusters with 1-letter amino acid representation\n",
    "clusters = {}\n",
    "for idx, cluster_id in enumerate(cluster_labels):\n",
    "    if cluster_id not in clusters:\n",
    "        clusters[cluster_id] = {\n",
    "            \"residues\": [],\n",
    "            \"rsa_values\": []\n",
    "        }\n",
    "    res_id, amino_one_letter = residue_coords[idx][0], residue_coords[idx][1]\n",
    "    clusters[cluster_id][\"residues\"].append(f\"{res_id}:{amino_one_letter}\")\n",
    "    clusters[cluster_id][\"rsa_values\"].append(rsa_values[idx])\n",
    "\n",
    "# Write clusters to a new CSV file for residue clusters with average RSA\n",
    "with open('residue_clusters.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Residue_Cluster\", \"Average_RSA\"])\n",
    "\n",
    "    for cluster in clusters.values():\n",
    "        avg_rsa = sum(cluster[\"rsa_values\"]) / len(cluster[\"rsa_values\"]) if cluster[\"rsa_values\"] else 0\n",
    "        writer.writerow([\";\".join(cluster[\"residues\"]), avg_rsa])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "169220a6-f38b-4b07-aa71-7ee0407e1472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hydrophilicity scale (Hopp-Woods scale)\n",
    "hydrophilicity_scale = {\n",
    "    'A': -0.5, 'R': 3.0, 'N': 0.2, 'D': 3.0, 'C': -1.0,\n",
    "    'Q': 0.2,  'E': 3.0, 'G': 0.0, 'H': -0.5, 'I': -1.8,\n",
    "    'L': -1.8, 'K': 3.0, 'M': -1.3, 'F': -2.5, 'P': 0.0,\n",
    "    'S': 0.3,  'T': -0.4, 'W': -3.4, 'Y': -2.3, 'V': -1.5\n",
    "}\n",
    "\n",
    "# Step 1: Update 'asa_rsa_output.csv' with hydrophilicity column\n",
    "# Re-open the existing CSV and add a hydrophilicity column without duplicating columns\n",
    "with open('asa_rsa_output.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    header = next(reader)  # Skip the header row\n",
    "    rows = list(reader)\n",
    "\n",
    "# Check if the header already contains \"Hydrophilicity\"\n",
    "if \"Hydrophilicity\" not in header:\n",
    "    header.append(\"Hydrophilicity\")\n",
    "\n",
    "# Calculate and add hydrophilicity values for each row\n",
    "for row in rows:\n",
    "    try:\n",
    "        residue_info = row[0]  # Format is \"position:amino\"\n",
    "        position, amino_one_letter = residue_info.split(':')\n",
    "        # Assign hydrophilicity based on the amino acid using Hopp-Woods scale\n",
    "        hydrophilicity = hydrophilicity_scale.get(amino_one_letter, 0)\n",
    "        # If the row already has the hydrophilicity column, update it, else append\n",
    "        if len(row) < len(header):\n",
    "            row.append(hydrophilicity)\n",
    "        else:\n",
    "            row[header.index(\"Hydrophilicity\")] = hydrophilicity\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing row {row}: {e}\")\n",
    "\n",
    "# Write the updated data back to 'asa_rsa_output.csv'\n",
    "with open('asa_rsa_output.csv', mode='w', newline='') as outfile:\n",
    "    writer = csv.writer(outfile)\n",
    "    writer.writerow(header)  # Write the updated header\n",
    "    writer.writerows(rows)  # Write all rows with updated hydrophilicity values\n",
    "\n",
    "# Step 2: Load residue hydrophilicity data from the updated 'asa_rsa_output.csv'\n",
    "residue_hydrophilicity = {}\n",
    "\n",
    "# Read the updated residue-level data including hydrophilicity\n",
    "with open('asa_rsa_output.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    header = next(reader)  # Skip the header row\n",
    "    for row in reader:\n",
    "        residue_info = row[0]  # Format is \"position:amino\"\n",
    "        position, amino = residue_info.split(':')\n",
    "        position = int(position)  # Convert position to an integer for easier lookup\n",
    "        hydrophilicity = float(row[header.index(\"Hydrophilicity\")])\n",
    "        residue_hydrophilicity[position] = hydrophilicity\n",
    "\n",
    "# Step 3: Update 'residue_clusters.csv' with average hydrophilicity column\n",
    "clusters_with_hydrophilicity = []\n",
    "\n",
    "with open('residue_clusters.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    header = next(reader)  # Skip the header row\n",
    "\n",
    "    # Ensure \"Average_Hydrophilicity\" is in the header\n",
    "    if \"Average_Hydrophilicity\" not in header:\n",
    "        header.append(\"Average_Hydrophilicity\")\n",
    "\n",
    "    for row in reader:\n",
    "        residues = row[0].split(';')  # Residues are in the format \"position:amino\"\n",
    "\n",
    "        # Calculate the average hydrophilicity for each cluster\n",
    "        total_hydrophilicity = 0\n",
    "        residue_count = 0\n",
    "        for residue in residues:\n",
    "            position, amino = residue.split(':')\n",
    "            position = int(position)\n",
    "            if position in residue_hydrophilicity:\n",
    "                total_hydrophilicity += residue_hydrophilicity[position]\n",
    "                residue_count += 1\n",
    "\n",
    "        # Compute the average hydrophilicity for the cluster\n",
    "        avg_hydrophilicity = total_hydrophilicity / residue_count if residue_count > 0 else 0\n",
    "\n",
    "        # Update row with the average hydrophilicity\n",
    "        if len(row) < len(header):  # If only the cluster information is present\n",
    "            row.append(avg_hydrophilicity)\n",
    "        else:\n",
    "            row[header.index(\"Average_Hydrophilicity\")] = avg_hydrophilicity\n",
    "        clusters_with_hydrophilicity.append(row)\n",
    "\n",
    "# Write the updated cluster data back to 'residue_clusters.csv'\n",
    "with open('residue_clusters.csv', mode='w', newline='') as outfile:\n",
    "    writer = csv.writer(outfile)\n",
    "    writer.writerow(header)  # Write the updated header\n",
    "    writer.writerows(clusters_with_hydrophilicity)  # Write all updated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "604e3dd5-e926-4e8d-8b63-d40e1ccd55f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Calculate B-factors for residues and update 'asa_rsa_output.csv'\n",
    "b_factors = []\n",
    "for residue in chain_structure.get_residues():\n",
    "    if residue.id[0] == ' ':\n",
    "        # Calculate the average B-factor for the residue\n",
    "        avg_b_factor = sum(atom.get_bfactor() for atom in residue) / len(residue)\n",
    "        b_factors.append(avg_b_factor)\n",
    "\n",
    "# Update 'asa_rsa_output.csv' to add or update B-factor column\n",
    "with open('asa_rsa_output.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    header = next(reader)\n",
    "    rows = list(reader)\n",
    "\n",
    "# Check if the header already contains \"B-Factor\"\n",
    "if \"B-Factor\" not in header:\n",
    "    header.append(\"B-Factor\")\n",
    "\n",
    "# Add or update B-factor values for each row\n",
    "for i, row in enumerate(rows):\n",
    "    try:\n",
    "        b_factor = b_factors[i] if i < len(b_factors) else 0\n",
    "        # If the row already has the B-factor column, update it; otherwise, append\n",
    "        if len(row) < len(header):\n",
    "            row.append(b_factor)\n",
    "        else:\n",
    "            row[header.index(\"B-Factor\")] = b_factor  # Use index of \"B-Factor\" in header\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing row {row}: {e}\")\n",
    "\n",
    "# Write the updated data back to 'asa_rsa_output.csv'\n",
    "with open('asa_rsa_output.csv', mode='w', newline='') as outfile:\n",
    "    writer = csv.writer(outfile)\n",
    "    writer.writerow(header)\n",
    "    writer.writerows(rows)\n",
    "\n",
    "# Step 2: Load residue B-factor data from 'asa_rsa_output.csv'\n",
    "residue_b_factor = {}\n",
    "with open('asa_rsa_output.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    header = next(reader)\n",
    "    for row in reader:\n",
    "        residue_info = row[0]  # Format is \"position:amino\"\n",
    "        position, amino = residue_info.split(':')\n",
    "        position = int(position)\n",
    "        b_factor = float(row[header.index(\"B-Factor\")])\n",
    "        residue_b_factor[position] = b_factor\n",
    "\n",
    "# Step 3: Update 'residue_clusters.csv' with average B-factor column\n",
    "clusters_with_b_factors = []\n",
    "with open('residue_clusters.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    header = next(reader)\n",
    "\n",
    "    # Ensure \"Average_B-Factor\" is in the header\n",
    "    if \"Average_B-Factor\" not in header:\n",
    "        header.append(\"Average_B-Factor\")\n",
    "\n",
    "    for row in reader:\n",
    "        residues = row[0].split(';')  # Residues are in the format \"position:amino\"\n",
    "\n",
    "        # Calculate the average B-factor for each cluster\n",
    "        total_b_factor = 0\n",
    "        residue_count = 0\n",
    "        for residue in residues:\n",
    "            position, amino = residue.split(':')\n",
    "            position = int(position)\n",
    "            if position in residue_b_factor:\n",
    "                total_b_factor += residue_b_factor[position]\n",
    "                residue_count += 1\n",
    "\n",
    "        # Compute the average B-factor for the cluster\n",
    "        avg_b_factor = total_b_factor / residue_count if residue_count > 0 else 0\n",
    "\n",
    "        # Update row with the average B-factor\n",
    "        if len(row) < len(header):\n",
    "            row.append(avg_b_factor)\n",
    "        else:\n",
    "            row[header.index(\"Average_B-Factor\")] = avg_b_factor\n",
    "        clusters_with_b_factors.append(row)\n",
    "\n",
    "# Write the updated cluster data back to 'residue_clusters.csv'\n",
    "with open('residue_clusters.csv', mode='w', newline='') as outfile:\n",
    "    writer = csv.writer(outfile)\n",
    "    writer.writerow(header)\n",
    "    writer.writerows(clusters_with_b_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e922f41b-2582-46ec-8542-3d4f96622906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charge scale for residues (basic, acidic, or neutral)\n",
    "charge_scale = {\n",
    "    'A': 0, 'R': 1, 'N': 0, 'D': -1, 'C': 0,\n",
    "    'Q': 0, 'E': -1, 'G': 0, 'H': 1, 'I': 0,\n",
    "    'L': 0, 'K': 1, 'M': 0, 'F': 0, 'P': 0,\n",
    "    'S': 0, 'T': 0, 'W': 0, 'Y': 0, 'V': 0\n",
    "}\n",
    "\n",
    "# Update the CSV to add Charge column\n",
    "with open('asa_rsa_output.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    header = next(reader)\n",
    "    rows = list(reader)\n",
    "\n",
    "# Check if the header already contains \"Charge\"\n",
    "if \"Charge\" not in header:\n",
    "    header.append(\"Charge\")\n",
    "\n",
    "# Add or update charge values for each row\n",
    "for row in rows:\n",
    "    try:\n",
    "        residue_info = row[0]  # Format is \"position:amino\"\n",
    "        _, amino = residue_info.split(':')\n",
    "        # Assign charge based on the amino acid\n",
    "        charge = charge_scale.get(amino, 0)\n",
    "        # If the row already has the charge column, update it, else append\n",
    "        if len(row) < len(header):\n",
    "            row.append(charge)\n",
    "        else:\n",
    "            row[header.index(\"Charge\")] = charge\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing row {row}: {e}\")\n",
    "\n",
    "# Write the updated data back to 'asa_rsa_output.csv'\n",
    "with open('asa_rsa_output.csv', mode='w', newline='') as outfile:\n",
    "    writer = csv.writer(outfile)\n",
    "    writer.writerow(header)  # Write the updated header\n",
    "    writer.writerows(rows)  # Write all rows with updated charge values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
